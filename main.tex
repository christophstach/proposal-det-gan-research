\documentclass[conference,onecolumn,compsoc]{IEEEtran}

\input{settings}

\begin{document}


\title{Proposal: Image Generation with GANs}

\author{
  \IEEEauthorblockN{Christoph Stach}
  \IEEEauthorblockA{
    Hochschule für Technik und Wirtschaft Berlin\\
    Fachbereich 4 - Angewandte Informatik\\
    s0555912@htw-berlin.de
  }
}
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}

\noindent
The research project in the field of computer science will be about image generation with Generative Adversarial Networks. The goal is to examine GANs and explore their capability of generating new unseen images of arbitrary datasets. This project, especially photorealistic images, are used, but the proposed application can also generate a different format. Generative Adversarial Networks is a research area of deep learning, where two (or more) Neural Networks are competing. In a standard GAN architecture, a Generator generates images from a random number vector. A discriminator decides if the image comes from the Generator or the real Dataset. The Generator continuously tries to fool the Discriminator and therefore creates images of increasing quality.

\end{abstract}


\section{Motivation}

\noindent
The first GAN implementations used Dense-layers to generate new data \cite{goodfellow2014generative}. Follow-up projects, like DCGAN, \cite{radford2016unsupervised} used Convulional layers better suited for computer vision and image tasks. Still, it was tough to train networks with the capability of generating larger images. Training often suffers from problems like Mode-Collapse. GANs require datasets of large size and sufficient computing power. For these reasons, GANs are an exciting research area, which highly motivates to explore them.


\section{Objective}

\noindent
The project aims to familiarize the author with Generative Adversarial Networks, their functionalities, features, pitfalls, and problems. Only by understanding GANs better it is possible to improve them in future projects.

\section{Procedure}

\noindent
The first step is to develop an MSG-GAN \cite{karnewar2020msggan} architecture built upon the DCGAN \cite{radford2016unsupervised} architecture but with additional skip-connections between the generator and the discriminator layers. Secondly, the WGAN loss \cite{arjovsky2017wasserstein} and gradient penalty \cite{gulrajani2017improved} need to be implemented. For further testing also the RaHinge-Loss and the RaLSGAN-Loss \cite{jolicoeurmartineau2018relativistic} will be created. Finally, the GAN will be tested and evaluated with different datasets and normalization methods between the layers.

\section{Requirements and constraints}

\noindent
As GANs need a lot of computing power and time to train, only images of 128x128 pixels will be generated in this project. The requirement is that the GAN architecture is implemented in PyTorch \cite{paszke2019pytorch} and trained with the \url{determined.ai} framework.

\section{Expected Results}

\noindent
The proposed GAN will generate images of photorealistic quality. However, the author expects that not all images will be indistinguishable from real images. There will be images with generation artifacts, which clearly show that a GAN architecture generated it. Also, interpolations between images are not expected to deliver good results.

\newpage

\section{Preliminary Structure}

\noindent
\begin{enumerate}
  \item Abstract
  \item Introduction
  \item Basics \cite{goodfellow2014generative}
  \item Technologies
  \begin{enumerate}
    \item WGAN-GP \cite{arjovsky2017wasserstein,gulrajani2017improved}
    \item MSG-GAN \cite{karnewar2020msggan}
    \item Adam \cite{kingma2017adam}
    \item Relativistic Discriminator Loss \cite{jolicoeurmartineau2018relativistic}
    \item Exponential Moving Average \cite{yazıcı2019unusual}
    \item Spectral Normalization \cite{miyato2018spectral}
  \end{enumerate}
  \item Implementation
  \item Evaluation
  \item Conclusion and future applications
\end{enumerate}

\printbibliography


\end{document}